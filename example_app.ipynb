{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI   \n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv(find_dotenv(), override = True)\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I can't provide real-time weather updates. To get the current weather in San Francisco, I recommend checking a reliable weather website or using a weather app.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 15, 'total_tokens': 45, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None} id='run-901e85a6-daa8-43eb-a83b-fe48118d39fd-0' usage_metadata={'input_tokens': 15, 'output_tokens': 30, 'total_tokens': 45, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "I can't provide real-time weather updates. To get the current weather in San Francisco, I recommend checking a reliable weather website or using a weather app.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = llm.invoke([HumanMessage(content = \"What is the weather in San Francisco?\")]) \n",
    "\n",
    "print(response)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm an AI and do not have access to real-time information. However, I can provide general information about San Francisco's climate.\\n\\nSan Francisco is known for its cool and foggy climate, with temperatures ranging from 40°F to 70°F (4°C to 21°C) throughout the year. The city's weather is influenced by the Pacific Ocean and the Golden Gate Strait, which keeps temperatures relatively mild.\\n\\nIn general, San Francisco's weather can be described as follows:\\n\\n* Summer (June to August): Cool and foggy, with highs around 65-70°F (18-21°C) and lows around 50-55°F (10-13°C).\\n* Autumn (September to November): Mild and sunny, with highs around 65-70°F (18-21°C) and lows around 50-55°F (10-13°C).\\n* Winter (December to February): Cool and wet, with highs around 50-55°F (10-13°C) and lows around 40-45°F (4-7°C).\\n* Spring (March to May): Mild and sunny, with highs around 60-65°F (15-18°C) and lows around 45-50°F (7-10°C).\\n\\nPlease note that these are general temperature ranges, and actual weather conditions can vary from year to year. For up-to-date weather information, I recommend checking a weather website or app.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 43, 'total_tokens': 334, 'completion_time': 1.167039671, 'prompt_time': 0.011847963, 'queue_time': 0.153077603, 'total_time': 1.178887634}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None} id='run-344b9bca-2032-469f-8591-a0ce7c7cca7b-0' usage_metadata={'input_tokens': 43, 'output_tokens': 291, 'total_tokens': 334}\n",
      "(\"I'm an AI and do not have access to real-time information. However, I can \"\n",
      " \"provide general information about San Francisco's climate.\\n\"\n",
      " '\\n'\n",
      " 'San Francisco is known for its cool and foggy climate, with temperatures '\n",
      " \"ranging from 40°F to 70°F (4°C to 21°C) throughout the year. The city's \"\n",
      " 'weather is influenced by the Pacific Ocean and the Golden Gate Strait, which '\n",
      " 'keeps temperatures relatively mild.\\n'\n",
      " '\\n'\n",
      " \"In general, San Francisco's weather can be described as follows:\\n\"\n",
      " '\\n'\n",
      " '* Summer (June to August): Cool and foggy, with highs around 65-70°F '\n",
      " '(18-21°C) and lows around 50-55°F (10-13°C).\\n'\n",
      " '* Autumn (September to November): Mild and sunny, with highs around 65-70°F '\n",
      " '(18-21°C) and lows around 50-55°F (10-13°C).\\n'\n",
      " '* Winter (December to February): Cool and wet, with highs around 50-55°F '\n",
      " '(10-13°C) and lows around 40-45°F (4-7°C).\\n'\n",
      " '* Spring (March to May): Mild and sunny, with highs around 60-65°F (15-18°C) '\n",
      " 'and lows around 45-50°F (7-10°C).\\n'\n",
      " '\\n'\n",
      " 'Please note that these are general temperature ranges, and actual weather '\n",
      " 'conditions can vary from year to year. For up-to-date weather information, I '\n",
      " 'recommend checking a weather website or app.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "\n",
    "llm_groq = ChatGroq(model = \"llama-3.1-70b-versatile\") \n",
    "\n",
    "response_2 = llm_groq.invoke([HumanMessage(content = \"What is the weather in San Francisco?\")])  \n",
    "\n",
    "print(response_2) \n",
    "pprint(response_2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph \n",
    "from typing_extensions import TypedDict \n",
    "from typing import Annotated \n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict): \n",
    "    question: str \n",
    "    answer: str\n",
    "    context: Annotated[list[str], add] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_exa import ExaSearchRetriever \n",
    "from langchain_core.prompts import PromptTemplate \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def exa_retrieve(input): # Later, try \"https://api.exa.ai/contents\" using a post request\n",
    "    exa_retriever = ExaSearchRetriever(k = 1, highlights = False)  \n",
    "    \n",
    "    document_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {url}\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    document_chain = RunnableLambda(lambda document: {\"url\": document.metadata[\"url\"]}) | document_prompt\n",
    "    \n",
    "    retrieval_chain = exa_retriever | document_chain.map() | (lambda docs: \"\\n\".join([i.text for i in docs]))\n",
    "    \n",
    "    output = retrieval_chain.invoke(input) \n",
    "    \n",
    "    return output\n",
    "\n",
    "# def exa_tool(state: State): \n",
    "#     question = State[\"question\"]\n",
    "\n",
    "exa_retriever_example = ExaSearchRetriever(k = 2, highlights = False) \n",
    "\n",
    "output_exa_retriever_example = exa_retriever_example.invoke(input = \"Latest premier league soccer games\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<class 'langchain_core.documents.base.Document'>, 'https://livescore.press/'), (<class 'langchain_core.documents.base.Document'>, 'https://www.livepremierleague.net/')]\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content='About  Our Service  \n",
      " \n",
      "strearning for an entire without any hassle.\n",
      "Livestream Football is the best destination football fans to Stream Football online without any commercial Ad breaks.\n",
      "Without cable. watch each an every football games live and replay in HD quality video using your hand horne smart\n",
      "gadgets.\n",
      " \n",
      "HELPFULL  FEATURES  \n",
      "Here you will get krow about our services, and lack what we provide far you.\n",
      "EVERY GAMES LIVE\n",
      "We offer global broadcast for\n",
      "Choose your Football sports events and\n",
      "start to watch Live Football streaming &amp; Replay\n",
      "whenever want.\n",
      "FULL HD CHANNELS\n",
      "We offer global broadcast for\n",
      "Get 350' HD Sports Channels, all\n",
      "available 24/7 LIVE &amp; On-Demand.\n",
      "Workable an every smart devices\n",
      "SUPPORT\n",
      "GLOBAL FULL ACCESS\n",
      "We offer global broadcast for\n",
      "Countries. No matter where you go\n",
      "With internet subscription is\n",
      "available all over the world.\n",
      "SUPPORT\n",
      "We offer 24/7 best in class customer support. At first contact and get feedback! Cancel Anytime.\n",
      " Choice Your Tv Plan\n",
      " \n",
      "  \n",
      "7.00$ For 10 Day(s)\n",
      "EPL Full Season Live\n",
      "All Motorsports Live\n",
      "Movies, TV Shows\n",
      "Price $ 7.00 \n",
      " $7.00 Join Now\n",
      " \n",
      "  \n",
      "35.00$ For 90 Day(s)\n",
      "EPL Full Season Live\n",
      "All Motorsports Live\n",
      "Movies, TV Shows\n",
      "Price $ 35.00 \n",
      " $35.00 Join Now\n",
      " \n",
      "  \n",
      "65.00$ For 6 Month(s)\n",
      "EPL Full Season Live\n",
      "All Motorsports Live\n",
      "Movies, TV Shows\n",
      "Price $ 65.00 \n",
      " $65.00 Join Now\n",
      " \n",
      "  \n",
      "90.00$ For 1 Year(s)\n",
      "EPL Full Season Live\n",
      "All Motorsports Live\n",
      "Movies, TV Shows\n",
      "Price $ 90.00 \n",
      " $90.00 Join Now' metadata={'title': 'Live Premier League 2022-23, News, Fixtures, Scores & Results', 'url': 'https://www.livepremierleague.net/', 'id': 'https://www.livepremierleague.net/', 'score': 0.165444478392601, 'published_date': '2022-07-31T00:00:00.000Z', 'author': ''}\n"
     ]
    }
   ],
   "source": [
    "print([(type(i), i.metadata[\"url\"]) for i in output_exa_retriever_example])\n",
    "# Implement string of langchain_core.documents.base.Document object\n",
    "print(type(output_exa_retriever_example[1]))\n",
    "print(output_exa_retriever_example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "    https://ftw.usatoday.com/lists/best-sports-games\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "output_exa_retrieve = exa_retrieve(\"Most exciting sports games ever\") \n",
    "\n",
    "print(type(output_exa_retrieve)) \n",
    "print(output_exa_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_content_urlopen(url: str): \n",
    "    response = urlopen(url) \n",
    "    example_html = response.read().decode(\"utf-8\") \n",
    "    soup = BeautifulSoup(example_html, \"html.parser\")\n",
    "    soup_str = str(soup)\n",
    "    return soup_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_read_content_urlopen = read_content_urlopen(\"https://python.langchain.com/docs/versions/v0_3/\") \n",
    "\n",
    "print(type(output_read_content_urlopen))\n",
    "print(\"-\" * 50) \n",
    "pprint(output_read_content_urlopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_read_content_urlopen[-15000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"The provided HTML code is for a documentation page of LangChain, a framework for building applications that leverage large language models. The page appears to be a guide for migrating code from LangChain 0.2 to LangChain 0.3.\\n\\nHere's a summary of the content:\\n\\n1. **Migrating using langchain-cli**: This section explains how to use the `langchain-cli` tool to migrate code from LangChain 0.2 to LangChain 0.3. It provides installation instructions, usage examples, and other options.\\n\\n2. **Usage**: This section provides examples of how to use the `langchain-cli` tool to migrate code. It explains that the tool should be run twice to apply all import replacements.\\n\\n3. **Other options**: This section lists additional options that can be used with the `langchain-cli` tool, including `--help`, `--diff`, and `--interactive`.\\n\\nThe page also includes a table of contents, a footer with links to the LangChain community, GitHub, and other resources, and a feedback section where users can provide feedback on the documentation.\\n\\nIn terms of code structure, the HTML code is well-organized and follows standard practices. It uses a combination of HTML elements, CSS classes, and JavaScript code to create a responsive and interactive documentation page. The code is also well-commented, making it easier for developers to understand and maintain.\\n\\nHowever, there are a few areas that could be improved:\\n\\n1. **Accessibility**: While the code includes some accessibility features, such as ARIA attributes and semantic HTML elements, there is room for improvement. For example, some images and icons are missing alt text, and some links are not clearly labeled.\\n\\n2. **Code organization**: While the code is generally well-organized, there are some areas where it could be improved. For example, some CSS classes are not clearly named, and some JavaScript code is not well-commented.\\n\\n3. **Performance**: The code includes some large images and scripts, which could impact page load times. Optimizing these assets could improve the overall performance of the page.\\n\\nOverall, the code is well-structured and follows standard practices, but there are some areas where it could be improved to make it more accessible, maintainable, and performant.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 463, 'prompt_tokens': 5621, 'total_tokens': 6084, 'completion_time': 1.8519999999999999, 'prompt_time': 1.462284722, 'queue_time': 0.006348722000000029, 'total_time': 3.314284722}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_9260b4bb2e', 'finish_reason': 'stop', 'logprobs': None} id='run-6e36d6e9-73c5-4b00-aa13-2629dcbe5382-0' usage_metadata={'input_tokens': 5621, 'output_tokens': 463, 'total_tokens': 6084}\n"
     ]
    }
   ],
   "source": [
    "html_llm_output = llm_groq.invoke([HumanMessage(content = output_read_content_urlopen[-15000:])]) \n",
    "\n",
    "print(html_llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "\n",
    "def html_chain(html: str): \n",
    "    prompt = ChatPromptTemplate.from_template(\"Summarize the following html: {html}\") \n",
    "\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    html_chain = prompt | llm_groq | parser \n",
    "    \n",
    "    output = html_chain.invoke({\"html\": html}) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided HTML code is for a documentation page of LangChain, a framework for building applications that leverage large language models. The page is a guide for migrating code from LangChain 0.2 to LangChain 0.3. The documentation includes the following sections:\n",
      "\n",
      "1. **Migrating using langchain-cli**: This section explains how to use the `langchain-cli` tool to migrate code from LangChain 0.2 to LangChain 0.3.\n",
      "\n",
      "2. **Usage**: This section provides examples of how to use the `langchain-cli` tool to migrate code.\n",
      "\n",
      "3. **Other options**: This section lists additional options that can be used with the `langchain-cli` tool.\n",
      "\n",
      "The HTML code is well-organized and follows standard practices, using a combination of HTML elements, CSS classes, and JavaScript code to create a responsive and interactive documentation page. However, there are some areas that could be improved, including:\n",
      "\n",
      "1. **Accessibility**: Some images and icons are missing alt text, and some links are not clearly labeled.\n",
      "\n",
      "2. **Code organization**: Some CSS classes are not clearly named, and some JavaScript code is not well-commented.\n",
      "\n",
      "3. **Performance**: Large images and scripts could impact page load times, and optimizing these assets could improve the overall performance of the page.\n",
      "\n",
      "Overall, the code is well-structured and follows standard practices, but there are some areas where it could be improved to make it more accessible, maintainable, and performant.\n"
     ]
    }
   ],
   "source": [
    "output_html_chain = html_chain(html_llm_output) \n",
    "\n",
    "print(output_html_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def read_content_json(url: str): \n",
    "#     response = urlopen(url)\n",
    "#     html = response.read().decode(\"utf-8\") \n",
    "#     data = json.loads(html) \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_read_content_json = read_content_json(\"https://ftw.usatoday.com/lists/best-sports-games\") \n",
    "\n",
    "# print(output_read_content_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "def read_content_bs4(url: str): \n",
    "    response = requests.get(url) \n",
    "    \n",
    "    if response.status_code == 200: \n",
    "        soup = BeautifulSoup(response, \"html.parser\") \n",
    "    \n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_read_content_bs4 = read_content_bs4(\"https://ftw.usatoday.com/lists/best-sports-games\") \n",
    "\n",
    "print(output_read_content_bs4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph_Project_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
